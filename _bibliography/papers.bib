---
---

@article{schnake2024symbolicxaiexplanation,
      title={Towards Symbolic XAI -- Explanation Through Human Understandable Logical Relationships Between Features}, 
      author={Schnake, T.* and Rezaei Jafari, F.* and Lederer, J and Xiong, P. and Nakajima, S. and Gugler, S. and Montavon, G. and Müller, K-R.},
      selected=True,
      preview={SymbXAI_logo.png},
      journal = {Information Fusion},
      abbr={Information Fusion},
      year = {2025},
      pdf = {https://www.sciencedirect.com/science/article/pii/S1566253524007012},
      contribution={equal},
abstract = {Explainable Artificial Intelligence (XAI) plays a crucial role in fostering transparency and trust in AI systems. Traditional XAI methods typically provide a single level of abstraction for explanations, often in the form of heatmaps in post-hoc attribution methods. Alternatively, XAI offers rule-based explanations that are expressive and composed of logical formulas but often fail to faithfully capture the model’s decision-making process or impose strict limitations on the model’s learning capabilities by requiring it to be inherently self-explainable. We aim to bridge these two approaches by developing post-hoc explanations that attribute relevance to complex logical relationships between input features while faithfully aligning with the model’s intricate prediction processes and imposing no restrictions on the model’s architecture. To this end, we propose a framework called Symbolic XAI, which attributes relevance to symbolic formulas expressing logical relationships between input features. Our method naturally extends propagation-based explanation approaches, such as layer-wise relevance propagation or GNN-LRP, and perturbation-based approaches, such as Shapley-values. Beyond relevance attribution of logical formulas for a model’s prediction, our framework introduces a strategy to automatically identify logical formulas that best summarize the model’s decision strategy, eliminating the need to predefine these formulas. We demonstrate the effectiveness of our framework in domains such as natural language processing (NLP), computer vision, and chemistry, where abstract symbolic domain knowledge is abundant and critically valuable to users. In summary, the Symbolic XAI framework provides a local understanding of the model’s decision-making process that is both flexible for customization by the user and human-readable through logical formulas.}
}

@article{jafari2024mambalrp,
      title={MambaLRP: Explaining Selective State Space Sequence Models},
      author={Rezaei Jafari, F. and Montavon, G. and Müller, K-R. and Eberle, O.},
      year={2024},
      selected=true,
      preview={MambaLRP_logo.gif},
      pdf=https://arxiv.org/pdf/2406.07592,
      website=https://github.com/FarnoushRJ/MambaLRP,
      journal={Conference on Neural Information Processing Systems (NeurIPS)},
      abbr={NeurIPS},
      abstract={We propose MambaLRP, a novel algorithm within the LRP framework, which ensures a more stable and reliable relevance propagation through these components. Our proposed method is theoretically sound and excels in achieving state-of-the-art explanation performance across a diverse range of models and datasets. Moreover, MambaLRP facilitates a deeper inspection of Mamba architectures, uncovering various biases and evaluating their significance. It also enables the analysis of previous speculations regarding the long-range capabilities of Mamba models.}
}


@article{ATS,
  title={Adaptive Token Sampling For Efficient Vision Transformers},
  author={Fayyaz, M.* and Abbasi Kouhpayegani, S.* and Rezaei Jafari, F.* and Sengupta, S. and Sommerlade, E. and Vaezi Joze, H. and Pirsiavash, H. and Gall, J.},
  journal={European Conference on Computer Vision (ECCV)},
  year={2022},
  pdf=https://arxiv.org/pdf/2111.15667.pdf,
  selected=true,
  preview={ATS_logo.gif},
  contribution={equal},
  website=https://adaptivetokensampling.github.io/,
  abbr={ECCV Oral},
  abstract={In this work, we therefore introduce a differentiable parameter-free Adaptive Token Sampler (ATS) module, which can be plugged into any existing vision transformer architecture. ATS empowers vision transformers by scoring and adaptively sampling significant tokens. As a result, the number of tokens is not constant anymore and varies for each input image. By integrating ATS as an additional layer within the current transformer blocks, we can convert them into much more efficient vision transformers with an adaptive number of tokens. Since ATS is a parameter-free module, it can be added to the off-the-shelf pre-trained vision transformers as a plug and play module, thus reducing their GFLOPs without any additional training. Moreover, due to its differentiable design, one can also train a vision transformer equipped with ATS. We evaluate the efficiency of our module in both image and video classification tasks by adding it to multiple SOTA vision transformers. Our proposed module improves the SOTA by reducing their computational costs (GFLOPs) by 2 times, while preserving their accuracy on the ImageNet, Kinetics-400, and Kinetics-600 datasets.}
}
